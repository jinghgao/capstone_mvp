# composer.py - Response Composition Layer (Adapted for Refactored Architecture)
from __future__ import annotations
from typing import Any, Dict, List, Optional, Tuple
import re

from fastapi import requests

# ========== LLM Integration (Ollama Only) ==========
try:
    from openai import OpenAI
    LLM_AVAILABLE = True
except ImportError:
    LLM_AVAILABLE = False
    print("[WARN] OpenAI library not available. Install: pip install openai")
    print("[INFO] Note: We use OpenAI library to connect to Ollama (local LLM)")

# Configuration - Local Ollama Only
OLLAMA_BASE_URL = "http://localhost:11434/v1"
OLLAMA_MODEL = "llama3.2:3b"  # æˆ– "mistral", "phi3"
OPENAI_MODEL = "gpt-4o-mini"
OLLAMA_MODEL_FALL_BACK = "llama3:8b" #"phi3:medium-128k"  # "wizard-math:7b"  "mistral" "llama3.2:3b"  æˆ– "mistral", "phi3"


# ========= Lightweight standards extraction (works well with short TXT standards) =========
_MOWING_METRIC_PATTERNS = [
    ("grass_length_cm", r"grass\s*length.*?(\d+\s*-\s*\d+)\s*cm", lambda s: s.replace(" ", "")),
    ("cutting_height_cm", r"cutting\s*height.*?(\d+(?:\.\d+)?)\s*cm", lambda s: s),
    ("drainage_max_hours", r"(?:percolation|standing\s*water).*?(\d+)\s*hour", lambda s: s),
    ("mowing_frequency", r"every\s+(\d+)\s+working\s+days", lambda s: s),
    ("weed_tolerance_pct", r"weed\s*tolerance.*?<\s*(\d+)\s*%", lambda s: s),
    ("bare_ground_pct", r"bare\s*ground.*?<\s*(\d+)\s*%", lambda s: s),
]

# extract mowing standards from text snippets
def _extract_mowing_standards_from_text(text: str) -> dict:
    found: Dict[str, str] = {}
    t = " ".join(line.strip() for line in (text or "").splitlines() if line.strip())
    for key, pat, norm in _MOWING_METRIC_PATTERNS:
        m = re.search(pat, t, flags=re.I)
        if m:
            try:
                found[key] = norm(m.group(1))
            except Exception:
                found[key] = m.group(1)
    return found

def _extract_mowing_standards_from_hits(hits: List[Dict[str, Any]]) -> dict:
    merged: Dict[str, str] = {}
    for h in hits[:3]:
        snippet = h.get("text", "") or ""
        if not snippet:
            continue
        cur = _extract_mowing_standards_from_text(snippet)
        for k, v in cur.items():
            if v and k not in merged:
                merged[k] = v
    return merged

# extract activity frequency from text snippets
def _extract_activity_frequency_from_hits(
    hits: List[Dict[str, Any]], activity_name: Optional[str]
) -> Dict[str, Any]:
    """
    Surface the first frequency line that matches the requested activity.
    """
    target = (activity_name or "").lower()
    best: Dict[str, Any] = {}

    for h in hits:
        text = h.get("text", "") or ""
        if not text:
            continue
        lines = [ln.strip() for ln in text.splitlines() if ln.strip()]
        freq_line = None
        for ln in lines:
            if "frequency" in ln.lower():
                freq_line = ln
                break
        if not freq_line:
            continue
        freq_text = re.sub(r"(?i)^[-â€¢]*\s*(\*\*frequency:\*\*|frequency:)\s*", "", freq_line).strip()
        entry = {
            "frequency": freq_text,
            "raw_line": freq_line,
            "source": h.get("source", ""),
            "snippet": text.strip()
        }
        if target and target in text.lower():
            return entry
        if not best:
            best = entry
    return best

def _estimate_cycle_days_from_text(text: Optional[str]) -> Optional[float]:
    """
    Convert textual frequency (e.g., '2â€“3 times per week') into approximate days per cycle.
    """
    if not text:
        return None
    t = text.lower()

    def _parse_range(m: re.Match) -> float:
        start = float(m.group(1))
        end = m.group(2)
        if end:
            return (start + float(end)) / 2.0
        return start

    # every X-Y weeks
    m = re.search(r"every\s+(\d+(?:\.\d+)?)\s*(?:-|â€“|â€”)?\s*(\d+(?:\.\d+)?)?\s*week", t)
    if m:
        return _parse_range(m) * 7.0

    # every X-Y days
    m = re.search(r"every\s+(\d+(?:\.\d+)?)\s*(?:-|â€“|â€”)?\s*(\d+(?:\.\d+)?)?\s*day", t)
    if m:
        return _parse_range(m)

    # X-Y times per week
    m = re.search(r"(\d+(?:\.\d+)?)\s*(?:-|â€“|â€”)?\s*(\d+(?:\.\d+)?)?\s*(?:times\s+)?per\s+week", t)
    if m:
        avg = _parse_range(m)
        if avg > 0:
            return 7.0 / avg

    if "biweekly" in t or "every other week" in t:
        return 14.0
    if "weekly" in t:
        return 7.0
    if "monthly" in t:
        return 30.0
    if "daily" in t or "every day" in t:
        return 1.0
    return None

    # ï¼ˆåˆ é™¤äº†é‡å¤çš„ mowing æ ‡å‡†æå–ä»£ç æ®µï¼‰
    # è¿™é‡ŒåŽŸæœ¬æ˜¯ä¸€æ®µä¸Žå‰é¢å®Œå…¨ç›¸åŒçš„ _MOWING_METRIC_PATTERNS /
    # _extract_mowing_standards_from_text / _extract_mowing_standards_from_hits å®žçŽ°ï¼Œ
    # ä¼šå¯¼è‡´å‡½æ•°å’Œå¸¸é‡é‡å¤å®šä¹‰ã€‚ä¿ç•™æ–‡ä»¶å‰é¢é‚£ä¸€ä»½å³å¯ï¼Œè¿™é‡Œå®‰å…¨åˆ é™¤ã€‚

# ========= RAG Context Summarization, with Fallback ==========
def _summarize_rag_context(
    rag_snippets: List[Dict[str, Any]],
    query: str,
    sql_result_summary: str = ""
) -> str:
    """
    Use local Ollama LLM to summarize RAG document snippets into coherent context.
    Falls back to simple formatting if LLM is unavailable or fails.
    """
    if not rag_snippets:
        return ""

    if not LLM_AVAILABLE:
        return _format_rag_snippets_simple(rag_snippets)
    try:
        context_text = "\n\n".join([
            f"Source {i+1} (page {snippet.get('page', '?')}): {snippet.get('text', '')[:500]}"
            for i, snippet in enumerate(rag_snippets[:3])
        ])

        common_tail = """
Guidelines:
- Never use placeholders like [insert ...] or [fill in ...]. If a value is unknown, omit it rather than inventing or leaving placeholders.
- Keep it concise and directly relevant. Use markdown formatting.
""".strip()

        if sql_result_summary:
            prompt = f"""You are an assistant helping interpret park maintenance data.

User Question: {query}

SQL Query Result: {sql_result_summary}

Reference Documents:
{context_text}

Task: Based on the reference documents, provide 2-3 sentences of relevant context that helps interpret the SQL results above. Focus on:
- Relevant standards, procedures, or guidelines
- Cost factors or typical ranges mentioned
- Any important notes about the data

{common_tail}"""
        else:
            prompt = f"""You are an assistant helping answer questions about park maintenance procedures and standards.

User Question: {query}

Reference Documents:
{context_text}

Task: Summarize the key information from the reference documents that answers the user's question. Provide:
- 2-3 key points or thresholds
- Relevant standards or guidelines
- Important safety/operational notes if applicable

{common_tail}"""

        client = OpenAI(base_url=OLLAMA_BASE_URL, api_key="ollama")

        response = client.chat.completions.create(
            model=OLLAMA_MODEL,
            messages=[
                {"role": "system", "content": "You are a helpful assistant that summarizes technical documentation clearly and concisely."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=300
        )
        
        summary = response.choices[0].message.content.strip()
        return summary
        
    except Exception as e:
        print(f"[WARN] LLM summarization failed: {e}")
        # å›žé€€åˆ°ç®€å•æ ¼å¼åŒ–
        return _format_rag_snippets_simple(rag_snippets)

def _summarize_rag_context_dimension_comparison(
    rag_snippets: List[Dict[str, Any]], 
    query: str,
    sql_result_summary: str = "",
    sql: str = "",
    field_type: str = ""
) -> Dict[str, Any]:

    # Default structured output matching prepare_data.generate_query's answer_ground_truth shape
    # print("HELLO WORLD")
    
    default_out: Dict[str, Any] = {
        "Home to Pitchers Plate": False,
        "Home to First Base Path": False,
        "Pitchers Plate Difference": None,
        "First Base Path Difference": None,
    }

    if not rag_snippets:
        return default_out
    
    try:
        import json
        import re
        if field_type == "diamond":
        # Build an instruction prompt that emphasizes strict JSON-only output
            prompt = (
                "You are a concise assistant that compares a field's numeric dimensions to the given standard. And produce ONLY a SINGLE JSON object with the comparison results (NO EXTRA TEXT or Markdown).\n\n"
                "INPUT:\n"
                "- question: " + (query or "") + "\n"
                "- context snippets (may contain the standard ranges and/or measured field values):\n"
            )
            for i, s in enumerate(rag_snippets or []):
                prompt += f"- snippet[{i}]: {s.get('text', s) if isinstance(s, dict) else str(s)}\n"
            if sql_result_summary:
                prompt += f"- sql_result_summary: {sql_result_summary}\n"

            prompt += (
                "\nINSTRUCTIONS:\n"
                "1) Identify the measured values for 'Home to Pitchers Plate' and 'Home to First Base Path' (meters) and the standard ranges for each.\n"
                "2) For each dimension, decide whether the measured value is within the standard range (True/False).\n"
                "3) If a dimension is outside the range, compute the difference in meters relative to the nearest bound:\n"
                "   - If measured < min: difference = measured - min (negative value)\n"
                "   - If measured > max: difference = measured - max (positive value)\n"
                "4) Output ONLY a single JSON object with these four keys (no extra text or Markdown):\n"
                '   {"Home to Pitchers Plate": <bool>, "Home to First Base Path": <bool>, '
                '"Pitchers Plate Difference": <number|None>, "First Base Path Difference": <number|None>}\n'
                "5) Use None for differences when the measured value is within range or missing.\n"
                "6) Numeric values should be plain numbers (floats allowed). Booleans must be true/false.\n"
            )
        else:
            prompt = (
                "You are a concise assistant that compares a field's numeric dimensions to the given standard.\n\n"
                "INPUT:\n"
                "- question: " + (query or "") + "\n"
                "- context snippets (may contain the standard ranges and/or measured field values):\n"
            )
            for i, s in enumerate(rag_snippets or []):
                prompt += f"- snippet[{i}]: {s.get('text', s) if isinstance(s, dict) else str(s)}\n"
            if sql_result_summary:
                prompt += f"- sql_result_summary: {sql_result_summary}\n"

            prompt += (
                "\nINSTRUCTIONS:\n"
                "1) Identify the measured values for 'Rectangular Field Length' and 'Rectangular Field Width' (meters) and the standard ranges for each. And produce ONLY a SINGLE JSON object with the comparison results (NO EXTRA TEXT or Markdown).\n"
                "2) For each dimension, decide whether the measured value is within the standard range (True/False).\n"
                "3) If a dimension is outside the range, compute the difference in meters relative to the nearest bound:\n"
                "   - If measured < min: difference = measured - min (negative value)\n"
                "   - If measured > max: difference = measured - max (positive value)\n"
                "4) Output ONLY a SINGLE JSON object with these four keys (NO EXTRA TEXT or Markdown):\n"
                '   {"Rectangular Field Length": <bool>, "Rectangular Field Width": <bool>, '
                '"Length Difference": <number|null>, "Width Difference": <number|null>}\n'
                "5) Use null for differences when the measured value is within range or missing.\n"
                "6) Numeric values should be plain numbers (floats allowed). Booleans must be true/false.\n"
            )
        if LLM_AVAILABLE:
            client = OpenAI(base_url=OLLAMA_BASE_URL, api_key="ollama")
            model = OLLAMA_MODEL_FALL_BACK
        else:
            client = OpenAI()  # may raise if not configured
            model = OPENAI_MODEL

        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0.0,
            max_tokens=512
        )
        """
        Used for testing online models
        import requests, json
        response = requests.post(
        url="https://openrouter.ai/api/v1/chat/completions",
        headers={
            "Authorization": "Bearer <YOUR_API_KEY>",
        },
        data=json.dumps({
            "model": "openai/gpt-4o", # Optional
            "messages": [
            {
                "role": "user",
                "content": prompt
            }
            ]
        })
        )
        summary = response.json().get("choices", [{}])[0].get("message", {}).get("content", "").strip()
        """
        summary = response.choices[0].message.content.strip()

        # Try strict JSON parse first
        try:
            parsed = json.loads(summary)
        except Exception:
            # Fallback: extract the first balanced JSON object substring
            parsed = None
            # find first '{' and find matching closing '}' by tracking depth
            start = summary.find('{')
            if start != -1:
                depth = 0
                for i in range(start, len(summary)):
                    if summary[i] == '{':
                        depth += 1
                    elif summary[i] == '}':
                        depth -= 1
                        if depth == 0:
                            candidate = summary[start:i+1]
                            try:
                                parsed = json.loads(candidate)
                            except Exception:
                                parsed = None
                            break
        return parsed or default_out

    except Exception as e:
        print(f"[WARN] Ollama LLM summarization failed: {e}")
        print(f"[INFO] Make sure Ollama is running and model is available (e.g., `ollama list`).")
        return default_out


def _format_rag_snippets_simple(snippets: List[Dict[str, Any]]) -> str:
    if not snippets:
        return ""
    output = "### Reference Context\n\n"
    for i, snippet in enumerate(snippets[:3], 1):
        text = snippet.get("text", "")
        text = re.sub(r'\s+', ' ', text).strip()
        text = text[:200] + "..." if len(text) > 200 else text
        page = snippet.get("page", "?")
        output += f"**Source {i}** (page {page}):\n{text}\n\n"
    return output


def _snip(txt: str, n: int = 150) -> str:
    s = re.sub(r"\s+", " ", (txt or "")).strip()
    return (s[:n] + "...") if len(s) > n else s

# ========== Main Composition Function being called externally ==========
def compose_answer(
    nlu: Dict[str, Any],
    state: Dict[str, Any],
    plan_metadata: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    # --- Early returns for unsupported or clarification flows ---
    status = state.get("status") or (plan_metadata or {}).get("status")
    if status == "UNSUPPORTED":
        msg = state.get("message") or "This question is not supported yet"
        return {
            "answer_md": f"**Not Supported**\n\n{msg}",
            "tables": [],
            "charts": [],
            "map_layer": None,
            "citations": [],
            "logs": state.get("logs", [])
        }

    clarifications = state.get("clarifications") or []
    if status == "NEEDS_CLARIFICATION" and clarifications:
        bullets = "\n".join([f"- {q}" for q in clarifications])
        return {
            "answer_md": f"**I need a bit more info to proceed:**\n\n{bullets}",
            "tables": [],
            "charts": [],
            "map_layer": None,
            "citations": [],
            "logs": state.get("logs", [])
        }

    intent = nlu.get("intent", "")
    ev = state.get("evidence", {})
    tables: List[Dict[str, Any]] = []
    citations: List[Dict[str, Any]] = []
    charts: List[Dict[str, Any]] = []
    answer_md = ""

    user_query = (
        nlu.get("raw_query", "") or
        nlu.get("slots", {}).get("text", "") or
        state.get("slots", {}).get("text", "")
    )

    template_hint = (plan_metadata or {}).get("template")
    if not template_hint:
        template_hint = _extract_template_from_logs(state.get("logs", []))

    slots = nlu.get("slots", {}) or state.get("slots", {})
    explanation_requested = bool(slots.get("explanation_requested"))

    activity_context: Dict[str, Any] = {}
    activity_cycle_days: Optional[float] = None

    header = []
    if intent:
        header.append(f"**Workflow:** `{intent}`")
    if template_hint:
        header.append(f"**Template:** `{template_hint}`")
    if header:
        answer_md = "  â€¢  ".join(header) + "\n\n"

    # ========== RAG content handling (updated for standards-style TXT) ==========
    if intent in ("RAG", "RAG+SQL_tool", "RAG+CV_tool"):
        kb_hits = ev.get("kb_hits", []) or []
        sop = ev.get("sop", {}) or {}

        domain = slots.get("domain", "generic")
        query_text = (user_query or "").lower()

        is_mowing_query = (
            domain == "mowing"
            or any(k in query_text for k in [
                "mowing", "mow", "turf", "grass", "lawn",
                "cutting height", "grass length"
            ])
        )

        standards = _extract_mowing_standards_from_hits(kb_hits) if kb_hits else {}
        rag_section_added = False

        if is_mowing_query and standards:
            answer_md += "**Maintenance Standards Summary**\n\n"
            lines = []
            if standards.get("grass_length_cm"):
                lines.append(f"- **Grass length**: {standards['grass_length_cm']}")
            if standards.get("cutting_height_cm"):
                lines.append(f"- **Cutting height**: {standards['cutting_height_cm']} cm")
            if standards.get("mowing_frequency"):
                lines.append(f"- **Mowing frequency**: every {standards['mowing_frequency']} working days")
            if standards.get("drainage_max_hours"):
                lines.append(f"- **Drainage**: no standing water within {standards['drainage_max_hours']} hour(s) after rain stops")
            if standards.get("weed_tolerance_pct"):
                lines.append(f"- **Weed tolerance**: < {standards['weed_tolerance_pct']}% coverage (typical)")
            if standards.get("bare_ground_pct"):
                lines.append(f"- **Bare ground**: < {standards['bare_ground_pct']}% of ground cover (typical)")

            if lines:
                answer_md += "\n".join(lines) + "\n"
            else:
                answer_md += "_Key metrics are not explicit in the current excerpt._\n"

            for h in kb_hits[:3]:
                citations.append({"title": "Maintenance Standards", "source": h.get("source", "")})
            rag_section_added = True

        if not rag_section_added and kb_hits and slots.get("domain") == "activity":
            activity_context = _extract_activity_frequency_from_hits(kb_hits, slots.get("activity_name"))
            freq_text = activity_context.get("frequency")
            if freq_text:
                activity_cycle_days = _estimate_cycle_days_from_text(freq_text)
                if activity_cycle_days:
                    activity_context["cycle_days"] = activity_cycle_days
                activity_label = (slots.get("activity_name") or "Requested activity").title()
                answer_md += "**Activity Frequency Reference**\n\n"
                freq_line = freq_text
                if activity_cycle_days:
                    freq_line += f" (~every {activity_cycle_days:.1f} days)"
                answer_md += f"- **{activity_label}**: {freq_line}\n"
                src = activity_context.get("source")
                if src:
                    citations.append({"title": "Activity Reference", "source": src})
                else:
                    for h in kb_hits[:2]:
                        citations.append({"title": "Activity Reference", "source": h.get("source", "")})
                rag_section_added = True

        if not rag_section_added and kb_hits and intent == "RAG":
            answer_md += "### Reference Summary\n\n"
            if LLM_AVAILABLE:
                try:
                    summary = _summarize_rag_context(
                        rag_snippets=kb_hits,
                        query=user_query or "Maintenance standards query",
                        sql_result_summary=""
                    )
                    answer_md += summary
                except Exception as e:
                    print(f"[WARN] LLM summary failed: {e}")
                    answer_md += _format_rag_snippets_simple(kb_hits)
            else:
                answer_md += _format_rag_snippets_simple(kb_hits)

            for h in kb_hits[:3]:
                citations.append({"title": "Maintenance Standards", "source": h.get("source", "")})

    # ========== SQL content handling ==========
    if intent in ("SQL_tool", "RAG+SQL_tool"):
        sql = ev.get("sql", {})
        rows = sql.get("rows") or []

        # Base data used by all SQL templates
        annotated_rows = rows
        due_groups: Dict[str, List[Dict[str, Any]]] = {}
        horizon_days: Optional[float] = None

        # ---- Template-specific enrichments / annotations ----
        # NOTE: When adding new SQL templates that need extra processing,
        #       follow this pattern and keep all template-specific logic
        #       in this section, before charts/tables/summary.
        if template_hint == "activity.maintenance_due_window":
            annotated_rows, due_groups, horizon_days = _annotate_due_rows(
                rows,
                activity_cycle_days,
                slots.get("weeks_ahead")
            )

        # TODO: add more template-specific post-processing here as needed
        # e.g.
        # elif template_hint == "some.new_template":
        #     annotated_rows = _post_process_new_template(rows, slots)

        # ---- Generic chart + table generation (template-agnostic) ----
        chart_config = _detect_chart_type(annotated_rows, template_hint)
        if chart_config:
            charts.append(chart_config)

        if annotated_rows:
            tables.append({
                "name": _get_table_name(template_hint, slots),
                "columns": list(annotated_rows[0].keys()),
                "rows": annotated_rows
            })

        # ---- Generic SQL summary generation ----
        sql_summary = _generate_sql_summary(annotated_rows, template_hint, slots)

        # ---- Template-specific summary augmentations ----
        if template_hint == "activity.maintenance_due_window":
            due_md = _format_due_window_summary(
                due_groups,
                horizon_days,
                activity_context,
                slots.get("weeks_ahead")
            )
            if due_md:
                sql_summary += "\n\n" + due_md

        # TODO: add more template-specific summary extensions here
        # e.g.
        # elif template_hint == "some.new_template":
        #     sql_summary += "\n\n" + _extra_summary_for_new_template(annotated_rows)

        # ---- Final answer composition for SQL part ----
        if answer_md:
            answer_md += "\n\n"

        answer_md += sql_summary
        answer_md += (
            f"\n\n**Query Performance**: "
            f"{sql.get('rowcount', 0)} rows in {sql.get('elapsed_ms', 0)}ms"
        )

        if intent == "RAG+SQL_tool":
            rag_hits = ev.get("kb_hits", [])
            if rag_hits:
                answer_md += "\n\n---\n\n"
                if nlu.get("slots", {}).get("domain") == "field_dimension":
                    field_type = slots.get("field_type")
                    rag_context = _summarize_rag_context_dimension_comparison(
                        rag_snippets=rag_hits,
                        query=user_query,
                        sql_result_summary=sql.get("rows",[]),
                        field_type=field_type
                    )
                    tables[0]["columns"].extend(list(rag_context.keys()))
                    tables[0]["rows"][0].update(rag_context)
                else:
                    rag_context = _summarize_rag_context(
                        rag_snippets=rag_hits,
                        query=user_query or "",
                        sql_result_summary=sql_summary
                    )
                answer_md += "Please see the table below. Note: This feature is unreliable and may produce incorrect results.\n\n"
                for h in rag_hits[:3]:
                    citations.append({"title": "Reference Document", "source": h.get("source", "")})

    # ========== CV content handling ==========
    if intent in ("CV_tool", "RAG+CV_tool"):
        cv = ev.get("cv", {})
        labels = cv.get("labels", [])
        is_mock = any("VLM not configured" in str(label) for label in labels) if isinstance(labels, list) else False

        if is_mock:
            answer_md += (
                ("\n\n" if answer_md else "") +
                "**Image Analysis (Not Configured)**\n\n"
                "To enable AI-powered image analysis:\n"
                "1. Get an API key from your provider (e.g., OpenRouter)\n"
                "2. Set environment variable: `export OPENROUTER_API_KEY='your-key'`\n"
                "3. Restart backend\n\n"
                "Supported analysis:\n"
                "- Field condition assessment\n"
                "- Turf health evaluation\n"
                "- Maintenance recommendations\n"
                "- Safety hazard detection"
            )
        else:
            answer_md += (
                ("\n\n" if answer_md else "") +
                "**Image Assessment**\n\n"
                f"Condition: **{cv.get('condition','unknown')}** (score {cv.get('score',0):.2f})\n\n"
                f"Issues: {', '.join(labels) if isinstance(labels, list) else labels}\n\n"
                f"Recommendations: {'; '.join(cv.get('explanations', [])) if isinstance(cv.get('explanations', []), list) else cv.get('explanations', '')}"
            )
            if cv.get("low_confidence"):
                answer_md = "> âš ï¸ Low confidence â€” consider uploading a clearer image.\n\n" + answer_md

        if intent == "RAG+CV_tool" and not is_mock:
            rag_hits = ev.get("kb_hits", [])
            if rag_hits:
                answer_md += "\n\n---\n\n"
                rag_context = _summarize_rag_context(
                    rag_snippets=rag_hits,
                    query=user_query or "",
                    sql_result_summary=""
                )
                answer_md += rag_context

        for h in ev.get("support", [])[:2]:
            citations.append({"title": "Reference Standards", "source": h.get("source", "")})

    if not answer_md:
        answer_md = "I couldn't generate a response for this query."

    return {
        "answer_md": answer_md,
        "tables": tables,
        "charts": charts,
        "map_layer": None,
        "citations": citations,
        "logs": state.get("logs", [])
    }


# ========== Helper Functions ==========

def _extract_template_from_logs(logs: List[Dict[str, Any]]) -> Optional[str]:
    return None

def _get_table_name(template_hint: Optional[str], slots: Dict[str, Any]) -> str:
    if not template_hint:
        return "Query Result"
    if template_hint == "mowing.labor_cost_month_top1":
        month = slots.get("month", "")
        year = slots.get("year", "")
        return f"Top Park by Mowing Cost ({month}/{year})"
    elif template_hint == "mowing.cost_trend":
        return "Mowing Cost Trend"
    elif template_hint == "mowing.cost_by_park_month":
        return "Cost Comparison by Park"
    elif template_hint == "mowing.last_mowing_date":
        return "Last Mowing Dates"
    elif template_hint == "mowing.cost_breakdown":
        return "Detailed Cost Breakdown"
    elif template_hint == "field_dimension.rectangular":
        return "Rectangular Field Dimension Comparison"
    elif template_hint == "field_dimension.diamond":
        return "Diamond Field Dimension Comparison"
    elif template_hint == "activity.maintenance_due_window":
        return "Maintenance Due Window"
    return "Query Result"

def _safe_get_field(row: Dict[str, Any], *names: str):
    """Return the first present field (case-insensitive), else None."""
    for name in names:
        if name in row:
            return row[name]
        up = name.upper()
        lo = name.lower()
        if up in row:
            return row[up]
        if lo in row:
            return row[lo]
    return None

def _generate_sql_summary(rows: List[Dict], template_hint: Optional[str], slots: Dict[str, Any]) -> str:
    """Generate natural language summary of SQL results."""
    if not rows:
        return "No results found."

    if template_hint == "mowing.labor_cost_month_top1":
        park = rows[0].get("park", "Unknown")
        cost = rows[0].get("total_cost", 0)
        month = slots.get("month", "")
        year = slots.get("year", "")
        return f"### ðŸ† Results\n\n**{park}** had the highest mowing cost of **${cost:,.2f}** in {month}/{year}."

    elif template_hint == "mowing.cost_trend":
        return f"### ðŸ“ˆ Trend Analysis\n\nCost trend data across **{len(rows)} time periods**."

    elif template_hint == "mowing.cost_by_park_month":
        total = sum(row.get("total_cost", 0) for row in rows)
        return f"### ðŸ“Š Cost Comparison\n\n**{len(rows)} parks** with combined costs of **${total:,.2f}**."

    elif template_hint == "mowing.last_mowing_date":
        # Prefer the requested park if provided, else first row
        park_name = (slots.get("park_name") or "").strip().lower()
        target = None
        if park_name:
            for r in rows:
                p = _safe_get_field(r, "park", "PARK")
                if p and str(p).strip().lower() == park_name:
                    target = r
                    break
        if target is None:
            target = rows[0]

        park = _safe_get_field(target, "park", "PARK") or "Unknown"
        date = _safe_get_field(target, "last_mowing_date", "LAST_MOWING_DATE", "date")
        sessions = _safe_get_field(target, "total_sessions", "TOTAL_SESSIONS", "total_mowing_sessions", "TOTAL_MOWING_SESSIONS")
        cost = _safe_get_field(target, "total_cost", "TOTAL_COST")

        parts = []
        if date:
            parts.append(f"**{park}** was last mowed on **{date}**")
        else:
            parts.append(f"Latest mowing record for **{park}** is shown below")

        if sessions is not None:
            parts.append(f"sessions: {sessions}")
        if cost is not None:
            try:
                parts.append(f"total cost: ${float(cost):,.2f}")
            except Exception:
                parts.append(f"total cost: {cost}")

        return "### ðŸ“… Last Mowing Activity\n\n" + "; ".join(parts) + "."

    elif template_hint == "mowing.cost_breakdown":
        return f"### ðŸ’° Detailed Breakdown\n\n**{len(rows)} cost entries** by activity type."
    
    elif template_hint == "field_dimension.rectangular":
        return f"### ðŸ“ Field Dimension Comparison\n\nComparing dimensions for **{len(rows)} rectangular fields**."
    elif template_hint == "field_dimension.diamond":
        return f"### ðŸ“ Field Dimension Comparison\n\nComparing dimensions for **{len(rows)} diamond fields**."
    elif template_hint == "activity.maintenance_due_window":
        weeks = slots.get("weeks_ahead")
        activity_name = (slots.get("activity_name") or "maintenance").title()
        window_text = f"the next {weeks} week(s)" if weeks else "the requested window"
        return f"### ðŸ›  Maintenance Window Check\n\nEvaluated **{len(rows)}** park(s) for **{activity_name}** over {window_text}."
    return f"### Results\n\nFound **{len(rows)} records**."

def _detect_chart_type(rows: List[Dict], template_hint: Optional[str] = None) -> Optional[Dict[str, Any]]:
    if not rows:
        return None

    columns = list(rows[0].keys())

    if template_hint == "mowing.cost_trend":
        if "month" in columns and "monthly_cost" in columns:
            parks = sorted(list(set(row.get("park") for row in rows if row.get("park"))))
            if len(parks) > 10:
                park_totals: Dict[str, float] = {}
                for park in parks:
                    park_totals[park] = sum(
                        row.get("monthly_cost", 0) for row in rows
                        if row.get("park") == park
                    )
                top_parks = sorted(park_totals.items(), key=lambda x: x[1], reverse=True)[:10]
                parks = [p[0] for p in top_parks]

            return {
                "type": "line",
                "title": "Mowing Cost Trend",
                "x_axis": {"field": "month", "label": "Month", "type": "category"},
                "y_axis": {"field": "monthly_cost", "label": "Cost ($)", "type": "value"},
                "series": [
                    {
                        "name": park,
                        "data": [
                            {"x": row["month"], "y": row["monthly_cost"]}
                            for row in rows if row.get("park") == park
                        ]
                    }
                    for park in parks
                ],
                "legend": True,
                "grid": True
            }

    elif template_hint in ["mowing.cost_by_park_month", "mowing.labor_cost_month_top1"]:
        if "park" in columns and "total_cost" in columns:
            return {
                "type": "bar",
                "title": "Mowing Cost by Park",
                "x_axis": {"field": "park", "label": "Park", "type": "category"},
                "y_axis": {"field": "total_cost", "label": "Total Cost ($)", "type": "value"},
                "series": [
                    {
                        "name": "Total Cost",
                        "data": [{"x": row["park"], "y": row["total_cost"]} for row in rows]
                    }
                ],
                "legend": False,
                "grid": True
            }

    elif template_hint == "mowing.last_mowing_date":
        if "park" in columns or "PARK" in columns:
            def get_field(row, *field_names):
                for field in field_names:
                    if field in row:
                        return row[field]
                    if field.upper() in row:
                        return row[field.upper()]
                    if field.lower() in row:
                        return row[field.lower()]
                return None

            return {
                "type": "timeline",
                "title": "Last Mowing Date by Park",
                "data": [
                    {
                        "park": get_field(row, "park", "PARK"),
                        "date": get_field(row, "last_mowing_date", "LAST_MOWING_DATE"),
                        "sessions": get_field(row, "total_sessions", "TOTAL_SESSIONS", "total_mowing_sessions", "TOTAL_MOWING_SESSIONS"),
                        "cost": get_field(row, "total_cost", "TOTAL_COST")
                    }
                    for row in rows
                ],
                "sort_by": "date",
                "sort_order": "desc"
            }
    elif template_hint == "activity.maintenance_due_window":
        if "location" in columns and "last_service_date" in columns:
            return {
                "type": "timeline",
                "title": "Last Service Date by Park",
                "data": [
                    {
                        "park": row.get("location"),
                        "date": row.get("last_service_date"),
                        "days_since": row.get("days_since_last"),
                        "status": row.get("due_status")
                    }
                    for row in rows
                ],
                "sort_by": "date",
                "sort_order": "desc"
            }

    return None

def _generate_chart_description(chart_config: Dict[str, Any], rows: List[Dict]) -> str:
    if not chart_config or not rows:
        return ""
    chart_type = chart_config.get("type")
    if chart_type == "line":
        parks = list(set(row.get("park") for row in rows if row.get("park")))
        months = sorted(set(row.get("month") for row in rows if row.get("month")))
        return f"Line chart comparing {len(parks)} park(s) from month {min(months)} to {max(months)}"
    elif chart_type == "bar":
        return f"Bar chart comparing {len(rows)} park(s)"
    elif chart_type == "timeline":
        return f"Timeline of last mowing dates for {len(rows)} park(s)"
    return ""

# ========== Specific SQL template helpers: maintenance due window ==========
def _safe_float(value: Any) -> Optional[float]:
    try:
        if value is None:
            return None
        return float(value)
    except (TypeError, ValueError):
        return None

def _annotate_due_rows(
    rows: List[Dict[str, Any]],
    cycle_days: Optional[float],
    weeks_ahead: Optional[int]
) -> Tuple[List[Dict[str, Any]], Dict[str, List[Dict[str, Any]]], Optional[float]]:
    """
    Add due status metadata to each row for maintenance window analysis.
    """
    if not rows:
        return rows, {}, None

    annotated: List[Dict[str, Any]] = []
    groups = {"overdue": [], "due": [], "recent": [], "unknown": []}

    horizon_days = _safe_float(rows[0].get("horizon_days"))
    if horizon_days is None and weeks_ahead:
        try:
            horizon_days = float(weeks_ahead) * 7.0
        except (TypeError, ValueError):
            horizon_days = None

    for row in rows:
        record = dict(row)
        days_since = _safe_float(record.get("days_since_last"))
        status = "unknown"
        days_until_due = None
        days_overdue = None

        if cycle_days is not None and days_since is not None:
            gap = cycle_days - days_since
            if gap <= 0:
                status = "overdue"
                days_overdue = abs(gap)
                days_until_due = 0.0
            else:
                if horizon_days is not None and gap <= horizon_days:
                    status = "due soon"
                else:
                    status = "recent"
                days_until_due = gap
                days_overdue = 0.0

        if cycle_days is not None:
            record["recommended_cycle_days"] = round(cycle_days, 2)
        if days_until_due is not None:
            record["days_until_due"] = round(days_until_due, 1)
        if days_overdue is not None:
            record["days_overdue"] = round(days_overdue, 1)
        record["due_status"] = status
        record["horizon_days"] = horizon_days
        annotated.append(record)

        group_key = "unknown"
        if status == "overdue":
            group_key = "overdue"
        elif status == "due soon":
            group_key = "due"
        elif status == "recent":
            group_key = "recent"
        groups.setdefault(group_key, []).append(record)

    return annotated, groups, horizon_days

def _format_due_window_summary(
    groups: Dict[str, List[Dict[str, Any]]],
    horizon_days: Optional[float],
    activity_context: Dict[str, Any],
    weeks_ahead: Optional[int]
) -> str:
    if not groups:
        return ""

    lines: List[str] = []
    freq = activity_context.get("frequency")
    cycle = activity_context.get("cycle_days")
    if freq:
        freq_line = f"**Reference frequency:** {freq}"
        if cycle:
            freq_line += f" (~every {cycle:.1f} days)"
        lines.append(freq_line)
    elif cycle:
        lines.append(f"**Reference frequency:** ~every {cycle:.1f} days")

    if horizon_days:
        weeks = horizon_days / 7.0
        window = weeks_ahead or round(weeks, 1)
        lines.append(f"**Planning window:** next {window} week(s) (~{horizon_days:.0f} days)")

    due_sections: List[str] = []
    for key, label in (("overdue", "Overdue"), ("due", "Due within window")):
        entries = groups.get(key) or []
        if not entries:
            continue
        block = [f"**{label}:**"]
        for rec in entries[:6]:
            park = rec.get("location") or rec.get("park") or "Unknown park"
            last_dt = rec.get("last_service_date") or "unknown date"
            days_since = rec.get("days_since_last")
            if days_since is not None:
                try:
                    days_since = float(days_since)
                except (TypeError, ValueError):
                    pass
            detail = f"- {park}: last serviced {last_dt}"
            if isinstance(days_since, (int, float)):
                detail += f" ({days_since:.1f} days ago)"
            if key == "overdue":
                overdue = rec.get("days_overdue")
                if isinstance(overdue, (int, float)) and overdue > 0:
                    detail += f", overdue by {overdue:.1f} day(s)"
            else:
                until = rec.get("days_until_due")
                if isinstance(until, (int, float)):
                    detail += f", due in ~{until:.1f} day(s)"
            block.append(detail)
        due_sections.append("\n".join(block))

    if not due_sections and groups.get("recent"):
        lines.append("All tracked parks are outside the requested window based on current records.")
    elif not due_sections and groups.get("unknown"):
        lines.append("Frequency reference was found but existing records are insufficient to determine upcoming needs.")

    if due_sections:
        lines.append("\n\n".join(due_sections))

    return "\n\n".join(lines).strip()